shishka@k3s-master-sakhalin:~$ cat bench.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: mcp-bench
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: egress-proxy
  namespace: mcp-bench
spec:
  replicas: 1
  selector:
    matchLabels:
      app: proxy
  template:
    metadata:
      labels:
        app: proxy
    spec:
      nodeSelector:
        kubernetes.io/hostname: k3s-worker-frankfurt
      containers:
      - name: tinyproxy
        image: vimagick/tinyproxy
        ports:
        - containerPort: 8888
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tool-sakhalin
  namespace: mcp-bench
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tool-remote
  template:
    metadata:
      labels:
        app: tool-remote
    spec:
      nodeSelector:
        kubernetes.io/hostname: k3s-master-sakhalin
      tolerations:
      - operator: "Exists"
      containers:
      - name: server
        image: python:3.11-slim
        command: ["/bin/sh", "-c"]
        args:
          - |
            pip install fastapi uvicorn -q
            cat <<EOF > main.py
            from fastapi import FastAPI
            import asyncio
            app = FastAPI()
            @app.get("/status")
            async def status():
                await asyncio.sleep(0.01)
                return {"status": "ok"}
            EOF
            uvicorn main:app --host 0.0.0.0 --port 8000
---
apiVersion: v1
kind: Service
metadata:
  name: tool-sakhalin-svc
  namespace: mcp-bench
spec:
  selector:
    app: tool-remote
  ports:
    - port: 80
      targetPort: 8000
---
apiVersion: v1
kind: Pod
metadata:
  name: bench-runner
  namespace: mcp-bench
spec:
  restartPolicy: Never
  nodeSelector:
    kubernetes.io/hostname: k3s-worker-moscow
  containers:
  - name: runner
    image: python:3.11-slim
    command: ["/bin/sh", "-c"]
    args:
      - |
        pip install google-generativeai httpx tabulate numpy matplotlib -q
        sleep 10
        cat <<EOF > benchmark.py
        import time, asyncio, os, httpx
        import google.generativeai as genai
        import numpy as np
        import matplotlib.pyplot as plt
        from tabulate import tabulate

        KEYS = [
            "key1",
            "key2",
            "key3" # Захардкожено
        ]

        PROXY_URL = "http://proxy-svc.mcp-bench.svc.cluster.local:8888"
        TOOL_URL = "http://tool-sakhalin-svc.mcp-bench.svc.cluster.local"

        os.environ["HTTPS_PROXY"] = PROXY_URL
        os.environ["HTTP_PROXY"] = PROXY_URL

        def get_model(iter_idx):
            key = KEYS[(iter_idx // 10) % len(KEYS)]
            genai.configure(api_key=key)
            return genai.GenerativeModel("models/gemini-2.0-flash-exp")

        async def topo_1x1_atomic():
            s = time.perf_counter()
            await asyncio.sleep(0.001)
            return (time.perf_counter() - s) * 1000

        async def topo_1xM_hub():
            async with httpx.AsyncClient(trust_env=False) as c:
                s = time.perf_counter()
                await c.get(TOOL_URL + "/status")
                return (time.perf_counter() - s) * 1000

        async def topo_Nx1_competing():
            async with httpx.AsyncClient(trust_env=False) as c:
                tasks = [c.get(TOOL_URL + "/status") for _ in range(15)]
                s = time.perf_counter()
                await asyncio.gather(*tasks)
                return (time.perf_counter() - s) * 1000

        async def topo_NxM_mesh():
            async with httpx.AsyncClient(proxy=PROXY_URL, trust_env=False, timeout=15.0) as c:
                s = time.perf_counter()
                await c.get(TOOL_URL + "/status")
                return (time.perf_counter() - s) * 1000

        async def run():
            results = {"1x1": [], "1xM": [], "Nx1": [], "NxM": []}
            print(f"Starting 30 iterations (3 keys x 10 requests)...")

            for i in range(30):
                model = get_model(i)
                try:
                    await model.generate_content_async("ping")
                except:
                    pass

                results["1x1"].append(await topo_1x1_atomic())
                results["1xM"].append(await topo_1xM_hub())
                results["Nx1"].append(await topo_Nx1_competing())
                results["NxM"].append(await topo_NxM_mesh())
                if (i + 1) % 5 == 0: print(f"Progress: {i+1}/30")

            table_data = []
            base_mean = np.mean(results["1x1"])
            for key in ["1x1", "1xM", "Nx1", "NxM"]:
                d = results[key]
                table_data.append([
                    key, f"{np.mean(d):.2f}", f"{np.median(d):.2f}",
                    f"{np.std(d):.2f}", f"{np.percentile(d, 90):.2f}",
                    f"{np.percentile(d, 99):.2f}", f"{np.mean(d)/base_mean:.1f}x"
                ])

            print("\n" + tabulate(table_data,
                headers=["Topo", "Mean", "Median", "Std", "P90", "P99", "Factor"],
                tablefmt="grid"))

            plt.figure(figsize=(12, 6))
            for key in results:
                plt.plot(results[key], label=key, marker='o', markersize=4)
            plt.title("Latency Distribution (30 Iters, Gemini 2.0 Flash)")
            plt.ylabel("Latency (ms)")
            plt.xlabel("Iteration")
            plt.yscale('log')
            plt.legend()
            plt.grid(True, which="both", ls="-", alpha=0.5)
            plt.savefig('/tmp/bench.png')

            print("\n" + "="*50)
            print("ЭКСПЕРИМЕНТ ЗАВЕРШЕН")
            print("Запустите эту команду на своем компьютере, чтобы забрать график:")
            print("kubectl cp mcp-bench/bench-runner:/tmp/bench.png ./bench_results.png")
            print("="*50 + "\n")

        asyncio.run(run())
        EOF
        python benchmark.py
        sleep 3600
